\newpage

\setcounter{page}{1}
\makecvfooter
  {Jerald Thomas}
  {Research Statement}
  {Page \thepage \hspace{1pt} of \pageref{research_last}}


\makecvheader[C]
\doublespacing

\cvsection{Research Statement}

Since 1965 when Ivan Sutherland published his seminal paper, ``The Ultimate Display", researchers have seen the potential for immersive technologies to transform how humans work, communicate, and entertain themselves. Thanks to modern technology, these potentials are beginning to be realized; this is evident by the significant impact virtual reality and other immersive technology devices have made on the consumer electronics market in the last decade. However, several practical and theoretical problems need to be solved to meet the general public’s expectations, resulting in immersive technologies restricted by how and where people can use them. The overarching goal of my research is to address fundamental usability problems of virtual and mixed reality, allowing for technologies that are more generalizable and applicable to the user's current situation and environment. Specifically, I am interested in making virtual and mixed reality technology more accessible to a larger population by creating and using forward-thinking human-computer interaction techniques and evaluating them with thorough and well-designed empirical studies.

\section*{Redirected Walking}
\vspace{-0.5cm}
As a Ph.D. student, I have focused on researching locomotion in virtual environments. Precisely, I have studied redirected walking, a technique that enhances natural locomotion. Natural locomotion translates the user’s movements in a tracked physical space to their virtual representation. Compared to less immersive locomotion techniques such as ``flying'' and ``teleporting,'' natural locomotion improves users' abilities to navigate the virtual environment, improves their subjective sense of presence, and does not induce additional simulator sickness.

However, natural locomotion comes with challenges, including compliance with physical boundaries and the additional risks of walking while wearing a virtual reality device. As these devices completely occlude the physical world from the user, they have to rely on the virtual reality system to keep them from walking into walls or tripping over obstacles. As a result, the consequence of improperly implementing the technique is much higher than other techniques. This additional risk is why most commercial virtual reality applications do not allow walking. If they do, it is restricted and generally used as a secondary means of locomotion.

Redirected walking is a novel solution to some of the problems introduced by natural locomotion. Previous research has shown that if there is a mismatch in the information provided by the visual and vestibular senses, the visual sense will dominate as long as the mismatch is not too severe. Redirected walking takes advantage of this mismatch to introduce manipulations that result in the user navigating a physical path different from their virtual path. The techniques used to introduce the manipulation are called self-motion gains. If the virtual reality system applies self-motion gains intelligently, the physical environment will increase in effective size, allowing the user to explore a larger virtual environment than with natural locomotion alone. Furthermore, the manipulations will remain imperceptible to the user if the system keeps the self-motion gains within established thresholds. Redirected walking algorithms determine which gains to apply at a given time and to what degree. My dissertation improves the current state of redirected walking by introducing novel redirected walking algorithms, and perhaps more importantly, new ways to use them.


\section*{Redirected Walking in Arbitrary Physical Spaces}
\vspace{-0.5cm}
Redirected walking algorithms have classically relied on three assumptions about the physical environment, namely that the physical environment is convex, free of obstacles, and static. ``Ideal’’ physical environments meet these requirements, where environments that do not satisfy one or more of these requirements are ``non-ideal.’’ Unfortunately, ideal physical environments are unrealistically restrictive and do not represent the majority of real-world environments.

I designed Push-Pull Reactive to address this problem directly. Push-Pull Reactive, which resides within a subclass of redirected walking algorithms termed reactive algorithms, uses techniques from the field of robotics to take a more intelligent approach in choosing gains compared to existing reactive algorithms. Evaluations show that Push-Pull Reactive performs as well as the previous state-of-the-art reactive algorithm in ideal physical environments, and it performs better in non-ideal environments. That work culminated in the paper, ``A General Reactive Algorithm for Redirected Walking Using Artificial Potential Functions,’’ presented at the IEEE Conference on Virtual Reality and 3D User Interactions in March 2019.


\section*{Physical Interaction in Redirected Walking Experiences}
\vspace{-0.5cm}
Nearly all current redirected walking implementations make it impossible for a virtual reality experience to employ both redirected walking and interactivity with the physical environment. Physical interactions are a very effective tool that virtual reality experience designers employ to create a more immersive and memorable experience. However, they require a specific relationship between the virtual and physical coordinate systems; redirected walking algorithms introduce a mismatch in this relationship, often non-deterministically. In practice, this means that a physical object and its virtual representation will become unaligned as redirected walking is applied. The inability of redirected walking algorithms to accommodate these interactions is one of their most notable drawbacks.

My solution to address this limitation uses redirected walking gains to essentially ``undo’’ the misalignment effects that redirected walking introduces as it attempts to avoid obstacles and boundaries. This technique, which I call environmental alignment, allows for physical environment interactions within pre-defined regions of the virtual environment and gives designers a powerful tool for increasing the immersiveness of their experiences. To the best of my knowledge, this is the first use of self-motion gains to accomplish tasks other than keeping the user away from physical boundaries and obstacles.

I first explored environmental alignment by extending the Push-Pull Reactive algorithm. The resulting paper titled ``Towards Physically Interactive Virtual Environments: Reactive Alignment with Redirected Walking'' was presented at the 2020 ACM Conference on Virtual Reality Systems and Technology, where it won the best paper award.

Reactive redirected walking algorithms, which have been the early focus of my dissertation research, have no knowledge of the user’s intended movements, which allows application in more general situations. However, more restrictive classes of redirected walking algorithms can perform better when applicable. These other classes, known as predictive algorithms, can procure information about the user’s intended movements to better select gain levels. To incorporate environmental alignment within a predictive algorithm, I am again turning to techniques developed in robotics literature. Specifically, I utilize inverse kinematics to find viable path solutions that end at a particular physical location. I plan on submitting this work, which will conclude my dissertation research, to the 2022 IEEE Conference on Virtual Reality and 3D User Interfaces in November 2021.

\section*{Research Supervising}
\vspace{-0.5cm}
I am currently mentoring a student on their first major research project. The project started during the final year of their undergraduate studies and has continued as they moved to a different university to start a Ph.D. program. The idea that I proposed to the student, which they ultimately decided to explore, is the introduction of a new redirected walking self-motion gain. Currently, there are three generally accepted self-motion gains. Each self-motion gain has a different pair of detection thresholds, which is the range of self-motion gain values that the average user will not detect. A poster presented at the 2019 ACM Symposium on Spatial User Interfaces showcased the concept and preliminary results, and a paper establishing the detection thresholds will be submitted to the 2022 IEEE Conference on Virtual Reality and 3D User Interfaces.

\section*{Future Research}
\vspace{-0.5cm}
I have derived some more general research questions regarding redirected walking while working on my dissertation, which has developed into a line of research that seeks to explore the physiological mechanisms required for redirected walking to work. This research comprises three sequential parts, each appropriately sized for myself and a small group of master’s students to undertake, and will address the following research questions.

First, how can self-motion gain detection thresholds be determined using an objective measure, and can this measure be used to adapt detection thresholds to the individual and the environment? Current redirected walking thresholds are determined using a purely subjective method that is long and laborious. A method that obtains objective measurements in a real-time fashion could significantly impact the field. Second, is there a difference in a user’s conscience and sub-conscience gain detection thresholds? As existing methods for measuring detection thresholds are subjective, they only obtain the user’s conscience thresholds. However, several researchers speculate that the user subconsciously detects the gain manipulations before they do so consciously. If this disparity exists, understanding it could result in greater efficiency of redirected walking techniques. Finally, how does suppression of the user’s vestibular response affect gain detection? The informational mismatch between the visual and vestibular senses is the proposed reason that redirected walking works. Therefore, suppressing the user’s vestibular response should affect the user’s perception of self-motion gains, and it should be possible to leverage this to make redirected walking more effective. This research would make a strong contender for the NSF Human-Centered Computing or CAREER grant opportunities.

With my dissertation research coming to an end, I am excited to pursue research opportunities in other areas. My wife is an occupational therapist, and through conversations with her and her colleagues, I have become very interested in exploring the use of virtual and augmented reality as tools for therapy and rehabilitation. For example, I have previously worked with Dr. Arshia Khan on a research proposal to explore the effectiveness of gamifying vestibular disorder diagnosis exams using a virtual reality headset equipped with eye-tracking. 

Vestibular disorders, or deficiencies regarding the vestibular system that affect everyday life, are prevalent among aging individuals. An extensive survey of adults living in the United States indicates that approximately 35\% of US adults over 40 have had some form of vestibular dysfunction. These vestibular disorders, which affect a person’s ability to maintain balance, are a significant contributor to falls among the elderly. Gamification will make the diagnosis experience more enjoyable and less fearful for the patients. It will also provide more options for clinicians seeking to administer these tests and, importantly, provide quantifiable data used in the rehabilitation process. Because the gamified tests will be built on relatively low-cost commodity hardware and will be largely automated, it will allow for vestibular deficiency testing in places that may not have access to a clinician or the otherwise necessary diagnostic tools. This research will make a strong grant proposal for the NSF/NIH Smart and Connected Health (SCH) solicitation or the NIH AREA or R21 grant opportunities.


\label{research_last}
